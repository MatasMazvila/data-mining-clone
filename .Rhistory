ggplot(kmedoids_data, aes(x = X1, y = X2)) +
geom_point(aes(color = cluster), size = 3, alpha = 0.8) +
geom_text(aes(label = title), size = 3, hjust = 0.5, vjust = -0.5, check_overlap = TRUE) +
scale_color_brewer(palette = "Set1") +
labs(
title = "K-Medoids Clustering (Faceted by Cluster)",
x = "MDS Dimension 1",
y = "MDS Dimension 2"
) +
facet_wrap(~ cluster, ncol = 3) +  # Separate each cluster into its own panel
theme_minimal() +
theme(
legend.position = "none",  # Remove legend since we are faceting
plot.title = element_text(hjust = 0.5, size = 14),
axis.title = element_text(size = 12),
axis.text = element_text(size = 10)
)
# Interactive plot with no channel names
plot <- ggplot(kmedoids_data, aes(x = X1, y = X2, color = cluster, text = title)) +
geom_point(size = 3, alpha = 0.8) +
scale_color_brewer(palette = "Set1") +
labs(
title = "K-Medoids Clustering (Interactive)",
x = "MDS Dimension 1",
y = "MDS Dimension 2"
) +
theme_minimal() +
theme(
plot.title = element_text(hjust = 0.5, size = 14),
axis.title = element_text(size = 12),
axis.text = element_text(size = 10)
)
ggplotly(plot, tooltip = "text")
library(Rtsne)
# Choose the optimal k
optimal_k <- 6
# Perform K-Medoids clustering with the chosen number of clusters
kmedoids_result <- pam(distance_matrix, k = optimal_k)
# Extract cluster labels
kmedoids_clusters <- kmedoids_result$clustering
# Add cluster labels to the original data
commenter_overlap$kmedoids_cluster <- kmedoids_clusters
# Multidimensional Scaling (MDS) for Visualization
mds_coords <- cmdscale(distance_matrix, k = 2)
# Prepare data for visualization
kmedoids_data <- data.frame(
X1 = mds_coords[, 1],
X2 = mds_coords[, 2],
cluster = as.factor(kmedoids_clusters),
title = commenter_overlap$title
)
# Plot the K-Medoids clustering result
ggplot(kmedoids_data, aes(x = X1, y = X2, color = cluster)) +
geom_point(size = 3, alpha = 0.8) +  # Points with transparency
geom_text(aes(label = title),        # Add channel names
size = 3, hjust = 0.5, vjust = -0.5, check_overlap = TRUE) +
labs(
title = "K-Medoids Clustering",
x = "MDS Dimension 1",
y = "MDS Dimension 2"
) +
theme_minimal() +
theme(
legend.position = "bottom",
plot.title = element_text(hjust = 0.5),
axis.title = element_text(size = 12),
axis.text = element_text(size = 10)
)
# Reduction to 2D
kmeans_data <- data.frame(X1 = mds_coords[, 1], X2 = mds_coords[, 2])
# Apply K-means clustering
set.seed(123)  # Set seed for reproducibility
num_clusters <- 6  # Set the number of clusters
kmeans_result <- kmeans(kmeans_data, centers = num_clusters, nstart = 25)
# Add cluster labels to the dataset
kmeans_data$cluster <- as.factor(kmeans_result$cluster)
# Visualize the clusters
ggplot(kmeans_data, aes(x = X1, y = X2, color = cluster)) +
geom_point(size = 3) +
geom_text(aes(label = commenter_overlap$title),
size = 3, hjust = 0.5, vjust = -0.5, check_overlap = TRUE) +
labs(
title = "K-Means Clustering",
x = "MDS Dimension 1",
y = "MDS Dimension 2"
) +
theme_minimal()
# Reduction to 2D
kmeans_data <- data.frame(X1 = mds_coords[, 1], X2 = mds_coords[, 2])
# Apply K-means clustering
set.seed(123)  # Set seed for reproducibility
num_clusters <- 6  # Set the number of clusters
kmeans_result <- kmeans(kmeans_data, centers = num_clusters, nstart = 25)
# Add cluster labels to the dataset
kmeans_data$cluster <- as.factor(kmeans_result$cluster)
# Visualize the clusters
ggplot(kmeans_data, aes(x = X1, y = X2, color = cluster)) +
geom_point(size = 3) +
geom_text(aes(label = commenter_jaccard$title),
size = 3, hjust = 0.5, vjust = -0.5, check_overlap = TRUE) +
labs(
title = "K-Means Clustering",
x = "MDS Dimension 1",
y = "MDS Dimension 2"
) +
theme_minimal()
# Scale the similarity matrix
scaled_matrix <- scale(similarity_matrix)
# Reduction to 2D
kmeans_data <- data.frame(X1 = mds_coords[, 1], X2 = mds_coords[, 2])
# Apply K-means clustering
set.seed(123)  # Set seed for reproducibility
num_clusters <- 6  # Set the number of clusters
kmeans_result <- kmeans(kmeans_data, centers = num_clusters, nstart = 25)
# Add cluster labels to the dataset
kmeans_data$cluster <- as.factor(kmeans_result$cluster)
# Visualize the clusters
ggplot(kmeans_data, aes(x = X1, y = X2, color = cluster)) +
geom_point(size = 3) +
geom_text(aes(label = commenter_overlap$title),
size = 3, hjust = 0.5, vjust = -0.5, check_overlap = TRUE) +
labs(
title = "K-Means Clustering",
x = "MDS Dimension 1",
y = "MDS Dimension 2"
) +
theme_minimal()
# Load the data (Matas)
channel_info <- read_csv("data/channel_info.csv")
commenter_jaccard <- read_csv("data/comment_jaccard_matrix.csv")
# Define similarity matrix
similarity_matrix <- as.matrix(commenter_jaccard[, -1])
# Ensure the similarity matrix is symmetric
similarity_matrix <- (similarity_matrix + t(similarity_matrix)) / 2
# Remove dimnames to avoid warnings
rownames(similarity_matrix) <- NULL
colnames(similarity_matrix) <- NULL
# Convert similarity matrix to a distance matrix
distance_matrix <- as.dist(1 - similarity_matrix)
# Convert the dist object to a full matrix for Elbow Method
distance_matrix_full <- as.matrix(distance_matrix)
# Reduction to 2D
kmeans_data <- data.frame(X1 = mds_coords[, 1], X2 = mds_coords[, 2])
# Apply K-means clustering
set.seed(123)  # Set seed for reproducibility
num_clusters <- 6  # Set the number of clusters
kmeans_result <- kmeans(kmeans_data, centers = num_clusters, nstart = 25)
# Apply K-means clustering
set.seed(123)  # Set seed for reproducibility
num_clusters <- 6  # Set the number of clusters
kmeans_result <- kmeans(kmeans_data, centers = num_clusters, nstart = 25)
# Add cluster labels to the dataset
kmeans_data$cluster <- as.factor(kmeans_result$cluster)
# Visualize the clusters
ggplot(kmeans_data, aes(x = X1, y = X2, color = cluster)) +
geom_point(size = 3) +
geom_text(aes(label = commenter_jaccard$title),
size = 3, hjust = 0.5, vjust = -0.5, check_overlap = TRUE) +
labs(
title = "K-Means Clustering",
x = "MDS Dimension 1",
y = "MDS Dimension 2"
) +
theme_minimal()
# Load the data (Matas)
channel_info <- read_csv("data/channel_info.csv")
commenter_overlap <- read_csv("data/comment_overlap_matrix.csv")
# Define similarity matrix
similarity_matrix <- as.matrix(commenter_overlap[, -1])
# Ensure the similarity matrix is symmetric
similarity_matrix <- (similarity_matrix + t(similarity_matrix)) / 2
# Remove dimnames to avoid warnings
rownames(similarity_matrix) <- NULL
colnames(similarity_matrix) <- NULL
# Convert similarity matrix to a distance matrix
distance_matrix <- as.dist(1 - similarity_matrix)
# Convert the dist object to a full matrix for Elbow Method
distance_matrix_full <- as.matrix(distance_matrix)
# Elbow Method to Determine Optimal k
k_values <- 2:15
total_wsd <- sapply(k_values, function(k) {
kmedoids_result <- pam(distance_matrix, k)
sum(sapply(1:k, function(cluster) {
cluster_members <- which(kmedoids_result$clustering == cluster)
cluster_distances <- distance_matrix_full[cluster_members, cluster_members]
sum(cluster_distances)
}))
})
# Plot the Elbow Curve
plot(k_values, total_wsd, type = "b", pch = 19, frame = FALSE,
xlab = "Number of Clusters (k)",
ylab = "Total Within-Cluster Sum of Distances",
main = "Elbow Method for K-Medoids")
# Print scores for inspection
print(data.frame(k = k_values, silhouette_score = silhouette_scores))
# Gap statistic
gap_stat <- clusGap(distance_matrix_full, FUN = pam, K.max = 15, B = 50)
# Plot the Gap Statistic
fviz_gap_stat(gap_stat)
# Inspect Gap Statistic
print(gap_stat)
# Choose the optimal k
optimal_k <- 6
# Perform K-Medoids clustering with the chosen number of clusters
kmedoids_result <- pam(distance_matrix, k = optimal_k)
# Extract cluster labels
kmedoids_clusters <- kmedoids_result$clustering
# Add cluster labels to the original data
commenter_overlap$kmedoids_cluster <- kmedoids_clusters
# Multidimensional Scaling (MDS) for Visualization
mds_coords <- cmdscale(distance_matrix, k = 2)
# Prepare data for visualization
kmedoids_data <- data.frame(
X1 = mds_coords[, 1],
X2 = mds_coords[, 2],
cluster = as.factor(kmedoids_clusters),
title = commenter_overlap$title
)
# Plot the K-Medoids clustering result
ggplot(kmedoids_data, aes(x = X1, y = X2, color = cluster)) +
geom_point(size = 3, alpha = 0.8) +  # Points with transparency
geom_text(aes(label = title),        # Add channel names
size = 3, hjust = 0.5, vjust = -0.5, check_overlap = TRUE) +
labs(
title = "K-Medoids Clustering",
x = "MDS Dimension 1",
y = "MDS Dimension 2"
) +
theme_minimal() +
theme(
legend.position = "bottom",
plot.title = element_text(hjust = 0.5),
axis.title = element_text(size = 12),
axis.text = element_text(size = 10)
)
# Each medoid in a separate panel
ggplot(kmedoids_data, aes(x = X1, y = X2)) +
geom_point(aes(color = cluster), size = 3, alpha = 0.8) +
geom_text(aes(label = title), size = 3, hjust = 0.5, vjust = -0.5, check_overlap = TRUE) +
scale_color_brewer(palette = "Set1") +
labs(
title = "K-Medoids Clustering (Faceted by Cluster)",
x = "MDS Dimension 1",
y = "MDS Dimension 2"
) +
facet_wrap(~ cluster, ncol = 3) +  # Separate each cluster into its own panel
theme_minimal() +
theme(
legend.position = "none",  # Remove legend since we are faceting
plot.title = element_text(hjust = 0.5, size = 14),
axis.title = element_text(size = 12),
axis.text = element_text(size = 10)
)
# Reduction to 2D
kmeans_data <- data.frame(X1 = mds_coords[, 1], X2 = mds_coords[, 2])
# Apply K-means clustering
set.seed(123)  # Set seed for reproducibility
num_clusters <- 6  # Set the number of clusters
kmeans_result <- kmeans(kmeans_data, centers = num_clusters, nstart = 25)
# Add cluster labels to the dataset
kmeans_data$cluster <- as.factor(kmeans_result$cluster)
# Visualize the clusters
ggplot(kmeans_data, aes(x = X1, y = X2, color = cluster)) +
geom_point(size = 3) +
geom_text(aes(label = commenter_overlap$title),
size = 3, hjust = 0.5, vjust = -0.5, check_overlap = TRUE) +
labs(
title = "K-Means Clustering",
x = "MDS Dimension 1",
y = "MDS Dimension 2"
) +
theme_minimal()
commenter_jaccard
commenter_jaccard <- read_csv("data/comment_jaccard_matrix.csv")
commenter_jaccard
View(commenter_jaccard)
View(commenter_overlap)
# Load the data (Matas)
channel_info <- read_csv("data/channel_info.csv")
commenter_jaccard <- read_csv("data/comment_jaccard_matrix.csv")
# Define similarity matrix
similarity_matrix <- as.matrix(commenter_jaccard[, -1])
# Ensure the similarity matrix is symmetric
similarity_matrix <- (similarity_matrix + t(similarity_matrix)) / 2
# Remove dimnames to avoid warnings
rownames(similarity_matrix) <- NULL
colnames(similarity_matrix) <- NULL
# Convert similarity matrix to a distance matrix
distance_matrix <- as.dist(1 - similarity_matrix)
# Convert the dist object to a full matrix for Elbow Method
distance_matrix_full <- as.matrix(distance_matrix)
# Elbow Method to Determine Optimal k
k_values <- 2:15
total_wsd <- sapply(k_values, function(k) {
kmedoids_result <- pam(distance_matrix, k)
sum(sapply(1:k, function(cluster) {
cluster_members <- which(kmedoids_result$clustering == cluster)
cluster_distances <- distance_matrix_full[cluster_members, cluster_members]
sum(cluster_distances)
}))
})
# Plot the Elbow Curve
plot(k_values, total_wsd, type = "b", pch = 19, frame = FALSE,
xlab = "Number of Clusters (k)",
ylab = "Total Within-Cluster Sum of Distances",
main = "Elbow Method for K-Medoids")
# Store average silhouette width for each k
silhouette_scores <- sapply(k_values, function(k) {
kmedoids_result <- pam(distance_matrix, k)
silhouette_result <- silhouette(kmedoids_result$clustering, dist(distance_matrix))
mean(silhouette_result[, 3])  # Average silhouette width
})
# Plot Silhouette Scores
plot(k_values, silhouette_scores, type = "b", pch = 19, frame = FALSE,
xlab = "Number of Clusters (k)",
ylab = "Average Silhouette Score",
main = "Silhouette Method for K-Medoids")
# Print scores for inspection
print(data.frame(k = k_values, silhouette_score = silhouette_scores))
# Gap statistic
gap_stat <- clusGap(distance_matrix_full, FUN = pam, K.max = 15, B = 50)
# Plot the Gap Statistic
fviz_gap_stat(gap_stat)
# Inspect Gap Statistic
print(gap_stat)
# Choose the optimal k (based on the Elbow Method, or use silhouette width)
optimal_k <- 7  # probably 6 or 8 according to Elbow
# Perform K-Medoids clustering with the chosen number of clusters
kmedoids_result <- pam(distance_matrix, k = optimal_k)
# Extract cluster labels
kmedoids_clusters <- kmedoids_result$clustering
# Add cluster labels to the original data
commenter_jaccard$kmedoids_cluster <- kmedoids_clusters
# Multidimensional Scaling (MDS) for Visualization
mds_coords <- cmdscale(distance_matrix, k = 2)
# Prepare data for visualization
kmedoids_data <- data.frame(
X1 = mds_coords[, 1],
X2 = mds_coords[, 2],
cluster = as.factor(kmedoids_clusters),
title = commenter_jaccard$title
)
# Plot the K-Medoids clustering result
ggplot(kmedoids_data, aes(x = X1, y = X2, color = cluster)) +
geom_point(size = 3, alpha = 0.8) +  # Points with transparency
geom_text(aes(label = title),        # Add channel names
size = 3, hjust = 0.5, vjust = -0.5, check_overlap = TRUE) +
labs(
title = "K-Medoids Clustering",
x = "MDS Dimension 1",
y = "MDS Dimension 2"
) +
theme_minimal() +
theme(
legend.position = "bottom",
plot.title = element_text(hjust = 0.5),
axis.title = element_text(size = 12),
axis.text = element_text(size = 10)
)
# Reduction to 2D
kmeans_data <- data.frame(X1 = mds_coords[, 1], X2 = mds_coords[, 2])
# Elbow Method for K-Means
set.seed(123)
k_values <- 2:15
wss <- sapply(k_values, function(k) {
kmeans_result <- kmeans(kmeans_data[, 1:2], centers = k, nstart = 25)
kmeans_result$tot.withinss
})
# Plot the Elbow Curve
plot(k_values, wss, type = "b", pch = 19, frame = FALSE,
xlab = "Number of Clusters (k)",
ylab = "Total Within-Cluster Sum of Squares (WSS)",
main = "Elbow Method for K-Means")
# Elbow Method for K-Means
set.seed(123)
k_values <- 2:15
wss_means <- sapply(k_values, function(k) {
kmeans_result <- kmeans(kmeans_data[, 1:2], centers = k, nstart = 25)
kmeans_result$tot.withinss
})
# Plot the Elbow Curve
plot(k_values, wss_means, type = "b", pch = 19, frame = FALSE,
xlab = "Number of Clusters (k)",
ylab = "Total Within-Cluster Sum of Squares (WSS)",
main = "Elbow Method for K-Means")
# Silhouette Analysis for K-Means
silhouette_scores_means <- sapply(k_values, function(k) {
kmeans_result <- kmeans(kmeans_data[, 1:2], centers = k, nstart = 25)
silhouette_result <- silhouette(kmeans_result$cluster, dist(kmeans_data[, 1:2]))
mean(silhouette_result[, 3])  # Average silhouette width
})
# Plot Silhouette Scores
plot(k_values, silhouette_scores_means, type = "b", pch = 19, frame = FALSE,
xlab = "Number of Clusters (k)",
ylab = "Average Silhouette Score",
main = "Silhouette Method for K-Means")
# Gap Statistic for K-Means
gap_stat_means <- clusGap(kmeans_data[, 1:2], FUN = kmeans, nstart = 25, K.max = 15, B = 50)
# Plot the Gap Statistic
fviz_gap_stat(gap_stat_means)
# Inspect Gap Statistic
print(gap_stat_means)
num_clusters <- 6
# Add cluster labels to the dataset
kmeans_data$cluster <- as.factor(kmeans_result$cluster)
# Visualize the clusters
ggplot(kmeans_data, aes(x = X1, y = X2, color = cluster)) +
geom_point(size = 3) +
geom_text(aes(label = commenter_jaccard$title),
size = 3, hjust = 0.5, vjust = -0.5, check_overlap = TRUE) +
labs(
title = "K-Means Clustering",
x = "MDS Dimension 1",
y = "MDS Dimension 2"
) +
theme_minimal()
# Scale similarity matrix
scaled_matrix <- scale(similarity_matrix)
# K-Distance Plot for eps
k <- 4  # Typically `minPts - 1`
knn_distances <- kNNdist(scaled_matrix, k = k)
knn_distances_sorted <- sort(knn_distances)
# Plot k-distance to determine the elbow point
plot(
1:length(knn_distances_sorted), knn_distances_sorted,
type = "l", col = "blue", lwd = 2,
xlab = "Points sorted by distance",
ylab = "k-NN Distance",
main = "k-Distance Plot for DBSCAN"
)
# Grid Search for Optimal Parameters
eps_values <- seq(0.01, 0.5, by = 0.01)  # Range of eps values to test
min_points_values <- 3:10  # Range of minPts values to test
# Store results
dbscan_scores <- expand.grid(eps = eps_values, minPts = min_points_values)
dbscan_scores$clusters <- NA
dbscan_scores$silhouette <- NA
for (i in 1:nrow(dbscan_scores)) {
eps <- dbscan_scores$eps[i]
minPts <- dbscan_scores$minPts[i]
# Perform DBSCAN
dbscan_result <- dbscan(scaled_matrix, eps = eps, minPts = minPts)
# Count clusters (excluding noise as cluster 0)
num_clusters <- length(unique(dbscan_result$cluster[dbscan_result$cluster > 0]))
dbscan_scores$clusters[i] <- num_clusters
# Calculate silhouette score if clusters exist
if (num_clusters > 1) {
silhouette_result <- silhouette(dbscan_result$cluster, dist(scaled_matrix))
dbscan_scores$silhouette[i] <- mean(silhouette_result[, 3], na.rm = TRUE)
}
}
# Inspect top results
optimal_parameters <- dbscan_scores[which.max(dbscan_scores$silhouette, na.rm = TRUE), ]
print(optimal_parameters)
# Inspect top results
optimal_parameters <- dbscan_scores[which.max(dbscan_scores$silhouette), ]
print(optimal_parameters)
# Define similarity matrix and scale it
scaled_matrix <- scale(similarity_matrix)
# Method 1: k-Distance Plot to Find Optimal `eps`
k <- 4  # Typically, k = minPts - 1
knn_distances <- kNNdist(scaled_matrix, k = k)
# Plot k-distance to find the "elbow"
plot(
sort(knn_distances), type = "l", col = "blue", lwd = 2,
xlab = "Points sorted by distance",
ylab = "k-NN Distance",
main = "k-Distance Plot for DBSCAN"
)
knn_distances
# Perform DBSCAN
dbscan_result <- dbscan(distance_matrix, eps = eps_value, minPts = min_points)
# Based on the elbow in the plot, choose a value for `eps`
eps_value <- 16  # Adjust based on the elbow in the k-distance plot
min_points <- 4    # Typical values are between 3 and 10
# Perform DBSCAN
dbscan_result <- dbscan(distance_matrix, eps = eps_value, minPts = min_points)
# Add cluster labels to the dataset
commenter_jaccard$dbscan_cluster <- dbscan_result$cluster
# Reduce dimensionality using MDS
mds_coords <- cmdscale(as.dist(1 - similarity_matrix), k = 2)
# Prepare data for visualization
visualization_data_dbscan <- data.frame(
X1 = mds_coords[, 1],
X2 = mds_coords[, 2],
cluster = as.factor(dbscan_result$cluster)
)
# Plot the clustering result
ggplot(visualization_data_dbscan, aes(x = X1, y = X2, color = cluster)) +
geom_point(size = 3) +
labs(
title = "DBSCAN Clustering Visualization",
x = "MDS Dimension 1",
y = "MDS Dimension 2"
) +
theme_minimal()
# Testing min points and eps values (we probably need a bigged data frame)
for (minPts_test in 1:4) {
for (eps_test in seq(0.05, 0.5, by = 0.05)) {
test_result <- dbscan(similarity_matrix, eps = eps_test, minPts = minPts_test)
cat("\nDBSCAN with eps =", eps_test, "and minPts =", minPts_test, "\n")
print(table(test_result$cluster))
}
}
# Testing min points and eps values (we probably need a bigged data frame)
for (minPts_test in 1:4) {
for (eps_test in seq(0.5, 17, by = 0.5)) {
test_result <- dbscan(similarity_matrix, eps = eps_test, minPts = minPts_test)
cat("\nDBSCAN with eps =", eps_test, "and minPts =", minPts_test, "\n")
print(table(test_result$cluster))
}
}
